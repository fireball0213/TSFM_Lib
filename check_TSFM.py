import argparse
from pathlib import Path

import numpy as np
import pandas as pd
from tabulate import tabulate

from Model_Path.model_zoo_config import Model_zoo_details, Model_abbrev_map, All_model_names
from utils.check_tools import (
    check_dataset_completeness,
    check_duplicate_results,
    check_model_naming,
    analyze_model_results,
    standardize_model_names,
    format_rank_summary_all,
    calculate_order_metrics,
)



def check_results_file(csv_file_path,verbose=False):
    """æ£€æŸ¥ç»“æœæ–‡ä»¶çš„å®Œæ•´æ€§å’Œä¸€è‡´æ€§"""
    try:
        df = pd.read_csv(csv_file_path)
    except Exception as e:
        print(f"æ— æ³•è¯»å–CSVæ–‡ä»¶: {e}")
        return None

    if verbose:
        print(f"\n{'=' * 50}\næ£€æŸ¥ç»“æœæ–‡ä»¶: {csv_file_path}")

    # 1. æ•°æ®é›†å®Œæ•´æ€§
    check_dataset_completeness(df, verbose)
    # 2. å»é‡
    df = check_duplicate_results(df, csv_file_path, verbose)
    # 3. æ¨¡å‹å‘½åæ£€æŸ¥
    check_model_naming(df, verbose)
    # 4. æ‰“å°å…¨å±€æŒ‡æ ‡ï¼ˆåªè¯»ï¼‰
    analyze_model_results(df, verbose)

    return df

def process_results(file_path, model_name, common_datasets, verbose=False):
    """åŠ è½½å¹¶å¤„ç†æ•°æ®æ–‡ä»¶çš„é€šç”¨å‡½æ•°"""
    if not file_path.exists():
        print(f"âŒ æ–‡ä»¶ç¼ºå¤±: {file_path}")
        return None

    df = check_results_file(file_path, verbose)
    if df is None:
        return None

    df["model"] = model_name
    df[['ds_key', 'ds_freq', 'term']] = df['dataset'].str.extract(r'^(.*?)/([^/]+)/([^/]+)$')
    df = df.rename(columns={
        'eval_metrics/MASE[0.5]': 'MASE',
        'eval_metrics/mean_weighted_sum_quantile_loss': 'CRPS',
        'eval_metrics/sMAPE[0.5]': 'sMAPE',
    })
    if 'model_order' in df.columns:
        df['model_order'] = df['model_order'].apply(
            lambda x: x.tolist() if hasattr(x, 'tolist') else
            [int(i) for i in x.strip('[]').split()] if isinstance(x, str) else x
        )
    df_return=df[df['dataset'].isin(common_datasets)].copy()
    return df_return


def summarize_baselines(baseline_df: pd.DataFrame, rank_base_list=None):
    """
    é˜¶æ®µä¸€ï¼šä»…å¯¹ baseline (cl_original) åšæ±‡æ€»ã€‚

    åŠŸèƒ½ï¼š
    - å¯¹ baseline å†…éƒ¨æŒ‰ rank_base åš dataset å†…æ’åï¼Œå¾—åˆ°å¹³å‡ RANK
    - æ‰“å° sMAPE / MASE / CRPS / RANK çš„å…¨å±€å‡å€¼è¡¨ï¼ˆåˆ—ä¸ºæ¨¡å‹ï¼Œä½¿ç”¨ç¼©å†™ï¼‰
    """
    if rank_base_list is None:
        rank_base_list = ["MASE", "sMAPE", "CRPS"]

    # ç»Ÿä¸€æŒ‡æ ‡å‘½åï¼Œå…¼å®¹ eval_metrics å‰ç¼€
    df = baseline_df.copy()
    df = df.rename(
        columns={
            "eval_metrics/MASE[0.5]": "MASE",
            "eval_metrics/mean_weighted_sum_quantile_loss": "CRPS",
            "eval_metrics/sMAPE[0.5]": "sMAPE",
        }
    )

    for rank_base in rank_base_list:
        if rank_base not in df.columns:
            print(f"âš ï¸ baseline ä¸­ä¸å­˜åœ¨ rank_base='{rank_base}'ï¼Œè·³è¿‡è¯¥æŒ‡æ ‡")
            continue

        df_ranked = df.copy()
        df_ranked["RANK"] = df_ranked.groupby("dataset")[rank_base].rank(
            method="min", ascending=True
        )

        metrics_to_show = ["sMAPE", "MASE", "CRPS", "RANK"]
        metrics_exist = [m for m in metrics_to_show if m in df_ranked.columns]
        if not metrics_exist:
            print(f"âš ï¸ baseline ä¸­æ²¡æœ‰å¯ç”¨æŒ‡æ ‡ï¼Œè·³è¿‡ rank_base={rank_base}")
            continue

        global_avg = df_ranked.groupby("model")[metrics_exist].mean().T
        global_avg = global_avg.reindex(metrics_exist).round(3)

        # æ‰“å°ç”¨åˆ—åæ›¿æ¢ä¸ºç¼©å†™
        print_df = global_avg.copy()
        print_df.columns = [
            Model_abbrev_map.get(str(c), str(c)) for c in print_df.columns
        ]

        print("\n" + "=" * 60)
        print(f"ğŸ“Š Baseline æ±‡æ€»è¡¨ï¼ˆrank_base = {rank_base}ï¼‰")
        print("=" * 60)
        print(
            tabulate(
                print_df,
                headers="keys",
                tablefmt="plain",
                floatfmt=".3f",
                numalign="decimal",
                stralign="left",
            )
        )


def summarize_selectors(
    combined_df: pd.DataFrame,
    zoo_model_name: str,
    verbose: bool = False,
    first_col_prefix: str | None = None,
    rank_base: str = "MASE",
    include_selector_in_rank: bool = False,
):
    """
    é˜¶æ®µäºŒï¼šå¯¹ baseline + selector åˆå¹¶åçš„ DataFrame åš rank è®¡ç®—ä¸ selector æ±‡æ€»ã€‚

    1ï¼‰æ ¹æ® rank_base æŒ‡å®šçš„æŒ‡æ ‡è®¡ç®—æ¯ä¸ª dataset å†…çš„æ¨¡å‹ rankï¼Œå¯ä»¥æ˜¯ 'MASE' / 'sMAPE' / 'CRPS'

    2ï¼‰æ˜¯å¦å°† selector ä¸€èµ·å‚ä¸ rank çš„è®¡ç®—ç”± include_selector_in_rank æ§åˆ¶ï¼š
        - include_selector_in_rank = Trueï¼š
            æ‰€æœ‰æ¨¡å‹ï¼ˆbaseline + selectorï¼‰ä¸€èµ· groupby('dataset') æ’å
            baseline çš„ rank ä¼šéšç€ selector è¡¨ç°å˜åŒ–è€Œå˜åŒ–
        - include_selector_in_rank = Falseï¼š
            å…ˆåªå¯¹ baseline æ’åï¼Œå†æŠŠ selector æŒ‰â€œæœ‰å¤šå°‘ baseline æ¯”å®ƒå¥½â€æ’å…¥æ’å
            baseline çš„ rank å®Œå…¨ä¸å— selector å˜åŒ–å½±å“ï¼ˆç¨³å®šï¼‰
    """
    df = combined_df.copy()

    df = df.rename(
        columns={
            "eval_metrics/MASE[0.5]": "MASE",
            "eval_metrics/mean_weighted_sum_quantile_loss": "CRPS",
            "eval_metrics/sMAPE[0.5]": "sMAPE",
        }
    )

    # æ”¯æŒä¼ åŸå§‹åˆ—åï¼Œç»Ÿä¸€æ˜ å°„åˆ° MASE/CRPS/sMAPE
    rank_base_map = {
        "eval_metrics/MASE[0.5]": "MASE",
        "eval_metrics/mean_weighted_sum_quantile_loss": "CRPS",
        "eval_metrics/sMAPE[0.5]": "sMAPE",
    }
    rank_base = rank_base_map.get(rank_base, rank_base)
    if rank_base not in df.columns:
        raise ValueError(f"rank_base='{rank_base}' ä¸åœ¨ DataFrame åˆ—ä¸­ï¼Œæ— æ³•è®¡ç®— RANK")

    # è®¡ç®— RANK åˆ—
    ranked_df = df.copy()
    rank_col = "RANK"

    # æƒ…å†µä¸€ï¼šä¸åŒºåˆ†ç‰¹æ®Šæ¨¡å‹ï¼Œæ‰€æœ‰æ¨¡å‹ä¸€èµ·æŒ‰æŒ‡æ ‡æ’å
    if zoo_model_name is None or include_selector_in_rank:
        ranked_df[rank_col] = ranked_df.groupby("dataset")[rank_base].rank(
            method="min", ascending=True
        )
    else:
        # æƒ…å†µäºŒï¼šbaseline ä¸ selector åˆ†å¼€å¤„ç†ï¼Œä¿è¯ baseline çš„ rank ç¨³å®š
        special_mask = ranked_df["model"] == zoo_model_name
        special_rows = ranked_df[special_mask].copy()
        other_rows = ranked_df[~special_mask].copy()

        # å…ˆå¯¹ baselineï¼ˆother_rowsï¼‰æŒ‰æŒ‡æ ‡æ’å
        other_rows[rank_col] = other_rows.groupby("dataset")[rank_base].rank(
            method="min", ascending=True
        )

        final_dfs = []
        for dataset, group in other_rows.groupby("dataset"):
            dataset_special = special_rows[special_rows["dataset"] == dataset].copy()

            if not dataset_special.empty:
                special_val = dataset_special[rank_base].values[0]
                # baseline ä¸­æœ‰å¤šå°‘æ¨¡å‹æ¯”å®ƒå¥½ï¼ˆæŒ‡æ ‡æ›´å°ï¼‰
                rank_pos = (group[rank_base] < special_val).sum() + 1
                dataset_special[rank_col] = rank_pos
                final_dfs.append(pd.concat([group, dataset_special]))
            else:
                final_dfs.append(group)

        if not final_dfs and not special_rows.empty:
            # åªæœ‰ selector æ²¡æœ‰ baseline çš„æç«¯æƒ…å†µ
            special_rows[rank_col] = 1
            ranked_df = special_rows
        else:
            ranked_df = pd.concat(final_dfs)

    df = ranked_df.sort_index()

    # 1ï¼‰å…¨å±€ï¼ˆæ‰€æœ‰æ¨¡å‹ï¼‰çš„å¹³å‡æŒ‡æ ‡ï¼Œå¯é€‰æ‰“å°
    metrics_to_show = ["sMAPE", "MASE", "CRPS", "RANK"]
    metrics_exist = [m for m in metrics_to_show if m in df.columns]
    if metrics_exist:
        global_avg = df.groupby("model")[metrics_exist].mean().T
        global_avg = global_avg.reindex(metrics_exist).round(4)

        if verbose:
            n_ds = df["dataset"].nunique()
            print(f"\nå…¨å±€å¹³å‡å€¼å…±æœ‰æ•°æ®é›†: {n_ds}, "
                  f"rank_base={rank_base}, include_selector_in_rank={include_selector_in_rank}")

            data = global_avg if isinstance(global_avg, pd.DataFrame) else global_avg.to_frame().T
            cols = list(data.columns)
            if first_col_prefix:
                first_cols = [c for c in cols if str(c).startswith(first_col_prefix)]
                other_cols = [c for c in cols if c not in first_cols]
                cols = first_cols + other_cols
                data = data[cols]

            header = ["Index"] + [str(c) for c in data.columns]
            print("\t".join(header))
            for idx in data.index:
                row = [str(idx)]
                for col in data.columns:
                    value = data.at[idx, col]
                    if pd.isna(value):
                        row.append("")
                    else:
                        row.append(f"{value:.3f}")
                print("\t".join(row))

    # 2ï¼‰ä»…æ„é€  selector å¯¹åº”çš„ä¸€åˆ—æ±‡æ€»ï¼ˆRank + æŒ‡æ ‡å‡å€¼ï¼‰
    filtered = df[df["model"] == zoo_model_name]
    table = pd.DataFrame(index=[], columns=[zoo_model_name])

    # Global è¡Œï¼šselector çš„å¹³å‡ RANK
    table.loc["Global", zoo_model_name] = filtered["RANK"].mean()

    # rank_base è¡Œï¼šselector çš„ rank_base æŒ‡æ ‡å¹³å‡å€¼
    if rank_base in filtered.columns:
        table.loc[rank_base, zoo_model_name] = filtered[rank_base].mean()

    # é¢å¤–é™„åŠ ä¸€ä¸ªå¸¸ç”¨æŒ‡æ ‡ï¼šsMAPEï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if "sMAPE" in filtered.columns:
        table.loc["sMAPE", zoo_model_name] = filtered["sMAPE"].mean()

    table = table.round(2)

    rank_summary = {"RANK": table}
    return rank_summary



def add_selector_rank(
    baseline_subset: pd.DataFrame,
    subset_df: pd.DataFrame,
    model_name: str,
    rank_summary_all: dict,
    add_index: int = 0,
    verbose: bool = True,
    df_real: pd.DataFrame | None = None,
    k_order=None,
    rank_base: str = "MASE",
    include_selector_in_rank: bool = False,
):

    combined_df = pd.concat([baseline_subset, subset_df], ignore_index=True)
    rank_summary = summarize_selectors(combined_df, zoo_model_name=model_name, verbose=verbose,rank_base=rank_base,include_selector_in_rank=include_selector_in_rank,)

    for rank_type in rank_summary_all:
        if rank_type in rank_summary and model_name not in rank_summary_all[rank_type].columns:
            rank_summary_all[rank_type].insert(add_index, model_name, rank_summary[rank_type][model_name])
            # æ·»åŠ orderæŒ‡æ ‡è®¡ç®—ç»“æœ
            if df_real is not None and 'model_order' in subset_df.columns and 'model_order' in df_real.columns:
                metrics = calculate_order_metrics(df_real, subset_df, k_order)
                for metric_name, value in metrics.items():
                    if metric_name not in rank_summary_all[rank_type].index:
                        rank_summary_all[rank_type].loc[metric_name] = np.nan
                    rank_summary_all[rank_type].loc[metric_name, model_name] = value
        elif model_name in rank_summary_all[rank_type].columns:
            print(f"âš ï¸ å·²å­˜åœ¨ '{model_name}' åˆ—ï¼Œè·³è¿‡æ’å…¥")

    return rank_summary_all




if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--verbose', action='store_true')
    args = parser.parse_args()

    results_dir = "results/"
    # =========================
    # 1ï¸âƒ£ baseline ç»“æœæ±‡æ€»
    # =========================

    baseline_rank_summary_all = {"RANK": pd.DataFrame()}

    for context_len in [512, 'original']:
        baseline_data_print = []
        for model_name in ['chronos_bolt_tiny','moirai_small','timesfm_2.5','sundial_base']:
        # for model_name in All_model_names:
            file_path = Path(results_dir) / model_name / f"cl_{context_len}" / "all_results.csv"
            if not file_path.exists():
                print(f"âš ï¸ baseline ç¼ºå°‘æ–‡ä»¶: {file_path}")
                continue

            df_print = check_results_file(file_path, verbose=args.verbose)
            if df_print is None:
                continue

            df_print["model"] = model_name
            baseline_data_print.append(df_print)

        if not baseline_data_print:
            print(f"âš ï¸ context_len={context_len} ä¸‹æ²¡æœ‰ä»»ä½•å¯ç”¨çš„ baseline ç»“æœï¼Œè·³è¿‡è¯¥å‚æ•°\n")
            continue
        baseline_df_print = pd.concat(baseline_data_print, ignore_index=True)

        # 1. æ‰“å°åˆ†è¡¨
        summarize_baselines(baseline_df_print, rank_base_list=["MASE"])

        # 2. ä¿å­˜ç»“æœï¼Œç”¨äºæ‰“å°è·¨å‚æ•°å¯¹æ¯”è¡¨
        df = baseline_df_print.rename(
            columns={
                "eval_metrics/MASE[0.5]": "MASE",
                "eval_metrics/mean_weighted_sum_quantile_loss": "CRPS",
                "eval_metrics/sMAPE[0.5]": "sMAPE",
            }
        )

        df["RANK"] = df.groupby("dataset")["MASE"].rank(method="min", ascending=True)

        avg_rank = df.groupby("model")["RANK"].mean()
        avg_mase = df.groupby("model")["MASE"].mean()
        avg_smape = df.groupby("model")["sMAPE"].mean() if "sMAPE" in df.columns else None

        for model_name in avg_rank.index:
            abbrev = Model_abbrev_map.get(model_name, model_name)

            model_column_name = f"{abbrev}_c_{context_len}"# ä½¿ç”¨ç¼©å†™ + context_len ä½œä¸ºåˆ—å

            if model_column_name not in baseline_rank_summary_all["RANK"].columns:
                baseline_rank_summary_all["RANK"][model_column_name] = np.nan

            baseline_rank_summary_all["RANK"].loc["Global", model_column_name] = avg_rank[model_name]
            baseline_rank_summary_all["RANK"].loc["MASE", model_column_name] = avg_mase[model_name]
            if avg_smape is not None:
                baseline_rank_summary_all["RANK"].loc["sMAPE", model_column_name] = avg_smape[model_name]

    print("\n" + "=" * 60 + "\nğŸ“Š Baseline æ‰€æœ‰å‚æ•°å–å€¼å¯¹æ¯”æ±‡æ€»è¡¨\n" + "=" * 60)
    print(
        tabulate(
            baseline_rank_summary_all["RANK"],
            headers="keys",
            tablefmt="plain",
            floatfmt=".3f",
            numalign="decimal",
            stralign="left",
        )
    )

    # =========================
    # 2ï¸âƒ£ selector å¯¹æ¯”
    # =========================

    # # è·å–å…¨éƒ¨ baseline TSFMæ¨¡å‹ç»“æœ
    # baseline_model_folders = All_model_names
    # print("baseline_model_folders", baseline_model_folders)
    #
    #
    # baseline_data = []
    # for model_name in baseline_model_folders:
    #     file_path = Path(results_dir) / model_name / "cl_512" /  "all_results.csv"
    #     if file_path.exists():
    #         print(f"\nğŸ”¹åŠ è½½ baseline : {model_name}",end=" ")
    #         df = check_results_file(file_path, args.verbose)
    #         if df is not None:
    #             df["model"] = model_name
    #             baseline_data.append(df)
    #     else:
    #         print(f"âŒ æœªæ‰¾åˆ°originalæ–‡ä»¶: {file_path}\n")
    #
    #
    # baseline_df = standardize_model_names(baseline_data)
    #
    # rank_summary_all = {"RANK": pd.DataFrame()}
    #
    # # éå†å„ä¸ªæ¨¡å‹å’Œå‚æ•°ä¸‹çš„ç»“æœ
    # # for model_size in ['chronos_bolt_tiny','moirai_small','timesfm_1.0','timesfm_2.0','visionts_base','sundial_base']:
    # for model_size in ['timesfm_1.0','timesfm_2.0','timesfm_2.5']:
    # #     for context_len in [36,96,512,1024,2048,4096]:
    #     for context_len in [96,256,512,1024,2048,5000,'original']:
    #
    #         result_file = Path(results_dir) / model_size / f"cl_{context_len}" / f"all_results.csv"
    #         if not result_file.exists():
    #             print(f"âŒ æ–‡ä»¶ç¼ºå¤±: {result_file}")
    #             continue
    #         result_df = check_results_file(result_file, args.verbose)
    #         if result_df is None:
    #             continue
    #         result_datasets = set(result_df['dataset'].unique())
    #         baseline_datasets = set(baseline_df['dataset'].unique())
    #         common_datasets = result_datasets & baseline_datasets
    #         # print(f"ğŸ“Š ä¸ baseline é‡åˆæ•°æ®é›†æ•°é‡: {len(common_datasets)}")
    #         baseline_subset = baseline_df[baseline_df['dataset'].isin(common_datasets)].copy()
    #
    #         # æ¨¡å‹ç¼©å†™
    #         model_family, model_variant = model_size.split('_', 1)
    #         abbreviation = Model_zoo_details[model_family][model_variant]["abbreviation"]
    #         model_column_name = f"{abbreviation}_c_{context_len}"
    #
    #         zoo_subset = process_results(result_file, model_column_name, common_datasets, verbose=True)
    #
    #         # ç»Ÿè®¡æ¯ä¸ª group çš„æ•°æ®é›†æ•°é‡
    #         dataset_counts_by_group = {}
    #         zoo_grouped = zoo_subset.copy()
    #
    #         for group_name in ['ds_freq', 'term', 'domain', 'num_variates']:
    #             if group_name == 'num_variates':
    #                 zoo_grouped['num_variates_group'] = zoo_grouped['num_variates'].apply(
    #                     lambda x: '=1' if x == 1 else '>1')
    #                 for group_val in ['=1', '>1']:
    #                     subset = zoo_grouped[zoo_grouped['num_variates_group'] == group_val]
    #                     dataset_counts_by_group[f"{group_name}:{group_val}"] = subset['dataset'].nunique()
    #             else:
    #                 for group_val in sorted(zoo_grouped[group_name].dropna().unique()):
    #                     subset = zoo_grouped[zoo_grouped[group_name] == group_val]
    #                     dataset_counts_by_group[f"{group_name}:{group_val}"] = subset['dataset'].nunique()
    #
    #         dataset_counts_by_group['Global'] = zoo_grouped['dataset'].nunique()
    #         dataset_counts_by_group['MASE'] = zoo_grouped['MASE'].nunique()
    #         dataset_counts_by_group['sMAPE'] = zoo_grouped['sMAPE'].nunique()
    #
    #
    #
    #         rank_summary_all = add_selector_rank(
    #             baseline_subset=baseline_subset,
    #             subset_df=zoo_subset,
    #             model_name=model_column_name,
    #             rank_summary_all=rank_summary_all,
    #             add_index=0,  # æ’å…¥ä½ç½®
    #             k_order=5, #è®¡ç®—orderæŒ‡æ ‡çš„Topkå€¼
    #             df_real=None,
    #             rank_base="MASE",# rank_base å¯ä»¥è‡ªç”±åˆ‡æ¢ï¼š'MASE' / 'sMAPE' / 'CRPS'
    #             include_selector_in_rank=False,  # æ§åˆ¶ selector æ˜¯å¦å‚ä¸ baseline æ’å
    #         )
    #
    # # æœ€ç»ˆæ ¼å¼åŒ–å¹¶æ‰“å°æ±‡æ€»è¡¨
    # rank_summary_all = format_rank_summary_all(rank_summary_all, dataset_counts_by_group)
    #
    # print("\n" + "=" * 60 + "\nğŸ“Š å¯¹æ¯”æ±‡æ€»è¡¨æ ¼\n" + "=" * 60)
    # for rank_type, df_summary in rank_summary_all.items():
    #     print(f"\nğŸ“ˆ Rank Type: {rank_type}")
    #
    #     # éšè—éšæœºç»“æœçš„è¯¦ç»†åˆ—ï¼Œåªä¿ç•™å¹³å‡å€¼åˆ—
    #     random_cols = [col for col in df_summary.columns if col.startswith('Rt') and not col.endswith('m')]
    #     cols_to_show = [col for col in df_summary.columns if col not in random_cols]
    #     df_summary_to_print = df_summary[cols_to_show]
    #
    #     # 5. æ‰“å°è¡¨æ ¼
    #     print(tabulate(
    #         df_summary_to_print,
    #         headers="keys",
    #         tablefmt="plain",  # æ¯” markdown æ›´ç´§å‡‘ï¼Œæ— ä»»ä½•è¾¹æ¡†æˆ–åˆ†éš”ç¬¦
    #         floatfmt=".3f",
    #         numalign="decimal",  # æ•°å­—å¯¹é½å°æ•°ç‚¹ï¼Œæ›´ç¾è§‚
    #         stralign="left"
    #     ))


